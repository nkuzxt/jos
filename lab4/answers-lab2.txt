#### Question 1

>Assuming that the following JOS kernel code is correct, what type should variable `x` have, `uintptr_t` or `physaddr_t`?
```
   mystery_t x;
   char* value = return_a_pointer();
   *value = 10;
   x = (mystery_t) value;
```
`uintptr_t`：`x`保存的是为`value`对应的地址，由于对`value`进行了解引用操作而且这个操作是“correct”的，所以可以得出`value`对应的地址是一个虚拟地址的结论，因此`x`的类型为`uintptr_t`。


##### Question 2
>What entries (rows) in the page directory have been filled in at this point? What addresses do they map and where do they point? In other words, fill out this table as much as possible:

|  Entry |Base Virtual Address|Points to (logically):|
|  1023  |     0xFFC00000     |Page table for top 4MB of phys memory|
|  1022  |     0xFF800000     |Page table for the next 4MB of phys memory|
|  .     |          ?         |?|
|  960   |     0xF0000000     |Page table for bottom 4MB of phys memory|
|  959   |     0xEFC00000     |Kernel Stack|
|  958   |     0xEF800000     |Memory-mapped I/O|
|  957   |     0xEF400000     |Read-only copies of page structures|
|  956   |     0xEF000000     |User read-only virtual page table|
|  .     |          ?         |?|
|  2     |     0x00800000     |?|
|  1     |     0x00400000     |?|
|  0     |     0x00000000     |[see next question]|

##### Question 3

>We have placed the kernel and user environment in the same address space. Why will user programs not be able to read or write the kernel's memory? What specific mechanisms protect the kernel memory?

Page Directory Entry和Page Table Entry中的低12位中保存了相关的权限位，包括`PTE_U`、`PTE_W`；`PTE_U`位表示用户特权，`PTE_W`位设置为1表示可写。根据[Intel® 64 and IA-32 Architectures Software Developer’s Manual](http://pdosnew.csail.mit.edu/6.828/2014/readings/ia32/IA32-3A.pdf)中，页目录项与页表项权限位设置与实际访问/读写权限的关系如下表所示：

![enter image description here](http://ww4.sinaimg.cn/large/6313a6d8jw1eq7bnrw8enj216k10i7g2.jpg)

在分页机制开启后，将虚拟内存映射到物理内存过程中，kernel会去检查权限位的设置，以实现保护。

##### Question 4

> What is the maximum amount of physical memory that this operating system can support? Why?

UPAGES区的大小为PTSIZE，所有的PageInfo都必须能放在其中，即最多有`PTSIZE/sizeof(PageInfo) = (PGSIZE*NPTENTRIES)/sizeof(PageInfo) = 512K`个PageInfo。

每个PageInfo对应1个物理页，即4096 Bytes。因此总的最大能覆盖的物理内存的大小是：$512K \times 4096 Bytes =  2 GBytes$。

##### Question 5

> How much space overhead is there for managing memory, if we actually had the maximum amount of physical memory? How is this overhead broken down?

Page Directory 需要 `1 * PGSIZE`
Page Tables 需要`NPTENTRIES * PGSIZE`
PageInfo数组需要`1 PTSIZE`(在内存中预留了这么多空间)
总计：`4K + 4M + 4M = 8M + 4K (Bytes)`

##### Question 6
> Revisit the page table setup in `kern/entry.S` and `kern/entrypgdir.c`. Immediately after we turn on paging, EIP is still a low number (a little over 1MB). At what point do we transition to running at an EIP above KERNBASE? What makes it possible for us to continue executing at a low EIP between when we enable paging and when we begin running at an EIP above KERNBASE? Why is this transition necessary?

```
   # kern/Entry.S
   
   59    # Turn on paging.
   60    movl  %cr0, %eax
   61    orl   $(CR0_PE|CR0_PG|CR0_WP), %eax
   62    movl  %eax, %cr0
   63  
   64    # Now paging is enabled, but we're still running at a low EIP
   65    # (why is this okay?).  Jump up above KERNBASE before entering
   66    # C code.
   67    mov   $relocated, %eax
   68    jmp   *%eax
   69  relocated:
   ...
```

`kern/Entry.S`中67、68两行非直接跳转到`relocated`，就是这两句话将`EIP`跳转到`KERNBASE`之上。

在开启分页之后、转移之前仍能在低地址运行时因为在`kern/entrypgdir.c`同时定义了从低地址`[0, 4MB)`和高地址`[KERNBASE, KERNBASE+4MB)`到物理内存`[0, 4MB)`的映射。

跳转到69行`relocated`之后`EIP`开始在`KERNBASE`之上跑。这个跳转是必要的是因为如果不进行跳转，则计算机并不知道下一条指令是在高地址还是在低地址，只会继续在低地址的范围运行。

#### Challenge 1

>We consumed many physical pages to hold the page tables for the KERNBASE mapping. Do a more space-efficient job using the PTE_PS ("Page Size") bit in the page directory entries. This bit was not supported in the original 80386, but is supported on more recent x86 processors. You will therefore have to refer to [Volume 3](http://pdosnew.csail.mit.edu/6.828/2014/readings/ia32/IA32-3A.pdf) of the current Intel manuals. Make sure you design the kernel to use this optimization only on processors that support it!

由 [the Intel manual](http://pdosnew.csail.mit.edu/6.828/2014/readings/ia32/IA32-3A.pdf)，

>**3.7.3. Mixing 4-KByte and 4-MByte Pages**
>When the PSE flag in CR4 is set, both 4-MByte pages and page tables for 4-KByte pages can be accessed from the same page directory. If the PSE flag is clear, only page tables for 4-KByte pages can be accessed (regardless of the setting of the PS flag in a page-directory entry).
>A typical example of mixing 4-KByte and 4-MByte pages is to place the operating system or executive’s kernel in a large page to reduce TLB misses and thus improve overall system performance.
The processor maintains 4-MByte page entries and 4-KByte page entries in separate TLBs. So, placing often used code such as the kernel in a large page, frees up 4-KByte-page TLB entries for application programs and tasks.

要打开`4M`页表首先要设置cr4中的`PSE`标志。之后在若将页目录项中的7号位`PS`置为1则可将其设置为`4M`模式，其页目录项的页基址直接指向内存中大小为`4MB`的物理页，对于未设置`PS`标志的则与之前一样指向大小为`4KB`的页表。

![enter image description here](http://ww1.sinaimg.cn/large/6313a6d8jw1eqadpc95psj212e0lojvi.jpg)

`4MB`的页目录项结构如上图所示，与`4KB`的页目录项和页表项的主要区别在于其中`[13,21]`位被设置为`0`，这是因为虚拟地址（如下图所示）中低21位`[0,20]`都要用被用来作为`Offset`，为了兼容性依然只有`[0,12]`位用于各种标记，因此`[13,21]`位就被保留为了`0`。

![enter image description here](http://ww3.sinaimg.cn/large/6313a6d8jw1eqadr81nlhj212s0l2ju9.jpg)

参考上面引用的Intel Manual的内容，`4MB`页的一个用法就是用`4MB`页来保存`kernel`部分的内容，并使用分别的`TLB`来管理，以降低访问内核的`TLB`miss率以及总体性能。

**具体实现**

首先在`kern/pmap.c mem_init()`中设置`cr4`：

```c
   // Set cr4 to enable 4-MByte paging
   cr4 = rcr4();
   cr4 |= CR4_PSE;
   lcr4(cr4);
```

并修改`KERNBASE`以上区域的映射时的全选设置，添加进`PTE_PS`标记：

```c
boot_map_region(kern_pgdir, KERNBASE, 0x10000000, 0, PTE_W | (PTE_PS & PSE_ENABLED));
```

其中`PSE_ENABLED`是自己定义的全局变量，用来开启/关闭`PSE`机制。

现在由于页目录项的结构有所变化，因此`boot_map_region`函数内部的实现也需要有所改变，在需要设置`PTE_PS`时，直接改变对应页目录项的值：

```
static void
boot_map_region(pde_t *pgdir, uintptr_t va, size_t size, physaddr_t pa, int perm)
{
   pte_t *ptep;
   uintptr_t cv;
   physaddr_t cp;

   if (perm & PTE_PS) {
      for (cv = 0, cp = pa; cv < size; cv += PTSIZE, cp += PTSIZE) {
         ptep = &pgdir[PDX(va + cv)];
         *ptep = cp | perm | PTE_P;
      }
   } else {
      for (cv = 0, cp = pa; cv < size; cv += PGSIZE, cp += PGSIZE) {
         ptep = pgdir_walk(pgdir, (const void *) (va + cv), 1);
         if (ptep)
            *ptep = cp | perm | PTE_P;
      }
   }
}
```

到这里`4MB`页的设置就完成了。但是如果这个时候执行`make grade`的话`check_va2pa`中会报错。这是因为`check_va2pa`将所有的页目录项一视同仁，进行两级的寻址；然而在`4MB`页开启之后，有些页目录项之后直接指向的是对应的物理页，而不能进行两级查找。因此我在`check_va2pa`中添加了如下代码作为应对：

```
if (*pgdir & PTE_PS & PSE_ENABLED)
   return PTE_ADDR(*pgdir) | (PTX(va) << PTXSHIFT);
```

这段代码只有在`PSE`机制开启后才会生效。

**测试运行结果**

在`qemu`中输入`info pg`打印出页表的状态：

![Page Table](http://ww3.sinaimg.cn/large/6313a6d8jw1eqatry3ea5j21160d0n49.jpg)

其中`PDE[3bd]`即为页目录的自映射，其中每一项对应着页目录中的每一项。`PDE[3c0-3d0]`、`PDE[3d1-3ff]`即为`KERNBASE`之上，也就是刚才设置为了`4MB`页模式的目录项。可以看到这两个目录项下并没有`PTE`，并且对应的物理页恰好覆盖了物理内存的前`256MB`。

现在`4MB`的静态映射虽然已经成功了，但是由于`JOS`的代码中目前物理页分配完全基于针对`4KB`页的PageInfo数组和空闲页链表，无法直接进行`4MB`页的动态分配。如果要实现对`4MB`页的分配就需要将整个物理页管理的方式进行重写过于复杂了`_(:з」∠)_`。目前这样也能工作暂且就不修改了。。


#### Challenge 2

>Extend the JOS kernel monitor with commands to:

>- Display in a useful and easy-to-read format all of the physical page mappings (or lack thereof) that apply to a particular range of virtual/linear addresses in the currently active address space. For example, you might enter 'showmappings 0x3000 0x5000' to display the physical page mappings and corresponding permission bits that apply to the pages at virtual addresses 0x3000, 0x4000, and 0x5000.
- Explicitly set, clear, or change the permissions of any mapping in the current address space.
- Dump the contents of a range of memory given either a virtual or physical address range. Be sure the dump code behaves correctly when the range extends across page boundaries!
- Do anything else that you think might be useful later for debugging the kernel. (There's a good chance it will be!)

实现了`mon_showmappings`、`mon_setperm`、`mon_dump`、`mon_shutdown`几个函数。前面3个函数有大量的处理格式化和边界的代码，并且针对了`4MB`页进行了处理，代码比较长，因此这里只写一下其中关键的功能部分。

**`mon_showmappings`**：使用`showmappings start_addr [end_addr]`，输出在`start_addr`和`end_addr`之间开始的页的映射。如果只输入`start_addr`，则输出`start_addr`之后第一个页的映射。

```
for (i = va1; va1 <= i && i <= va2; i = pttop) {
   if (over || flushscreen(count, 20, 1))
      break;
   pttop = ROUNDUP(i+1, PTSIZE);
   pdep = &kern_pgdir[PDX(i)];
   if (pdep && (*pdep & PTE_P)) {
      if (!(*pdep & PTE_PS)) {
         // 4-KByte
         for (i; i < pttop; i += PGSIZE) {
            if ((over = (flushscreen(count, 20, 1) == 1 || 
               i > va2 || i < va1)))
               break;
            ptep = pgdir_walk(kern_pgdir, (const void *)i, 0);
            if (ptep &&(*ptep & PTE_P))
               printmap(ptep, i, PGSIZE);
            else // pte unmapped
               printmap(ptep, i, -PGSIZE);   
            count++;
         }
      } else {
         // 4-MByte
         printmap(pdep, ROUNDDOWN(i, PTSIZE), PTSIZE);
         count++;
      }
   } else {
      // pde unmapped
      printmap(pdep, i, -PTSIZE);
      count++;
   }
}
```
外层循环与页表为单位执行，内层循环以页为单位执行。其中`flushscreen`在输出过多时使用，每20行提示一次是否要停止输出；`printmap`负责格式化输出每一行的结果。

![test](http://ww3.sinaimg.cn/large/6313a6d8jw1eqaus5ni0rj21100n27ia.jpg)

测试输入：`showmappings 0xef000000 0xffff0000`，从kernel stack顶部几个页到`KERNBASE`底部几个页的映射情况，可以看出输出结果正常：`KERNBASE`之下前8块页为`CPU0' kernel stack`的内容，在此之前为`Invalid Memory`，因此映射显示为`no mapping`；`KERNBASE`之上为`4MB`的页，因此以`4-MByte`为单位进行显示。

**`mon_setperm`**：使用`setperm addr [+|-]perm`，`perm`可为`P`、`U`、`W`其中之一或组合，大小写无关。在终端会先后输出对`addr`**所在的页**修改权限前的状态和修改后的结果。

```
pdep = &kern_pgdir[PDX(addr)];
if (pdep) { // no need to judge whether PTE_P stands
   if (*pdep & PTE_PS) {
      // 4-MByte
      addr = ROUNDDOWN(addr, PTSIZE);
      printmap(pdep, addr, PTSIZE);
      setperm(pdep, perms);
      cprintf(" ---->\n");
      printmap(pdep, addr, PTSIZE);
   } else {
      // 4-KByte
      ptep = pgdir_walk(kern_pgdir, (const void *) addr, 0);
      if (ptep) {
         printmap(ptep, addr, PGSIZE);
         setperm(ptep, perms);
         cprintf(" ---->\n");
         printmap(ptep, addr, PGSIZE);
      } else
         printmap(ptep, addr, -PGSIZE);
   }
} else {
   // pde unmapped
   addr = ROUNDDOWN(addr, PTSIZE);
   printmap(pdep, addr, -PTSIZE);
}
```
`perms`数组的内容由输入而定，`perm`串以`+`开头或直接以`P`、`U`、`W`开头的情况为1，以`-`开头则为`-1`，除此之外的情况为`0`。权限设置的功能由`setperm`实现：

```
void
setperm(pte_t *ptep, int perms[])
{
   if (perms[0] == 1)
      *ptep |= PTE_P;
   else if (perms[0] == -1)
      *ptep &= ~PTE_P;
   if (perms[1] == 1)
      *ptep |= PTE_U;
   else if (perms[1] == -1)
      *ptep &= ~PTE_U;
   if (perms[2] == 1)
      *ptep |= PTE_W;
   else if (perms[2] == -1)
      *ptep &= ~PTE_W;
}
```

测试权限增减：

![test setperm](http://ww2.sinaimg.cn/large/6313a6d8jw1eqavggcaxkj213g08owi7.jpg)

测试`4MB`页权限设置：

![test setperm 4mb](http://ww2.sinaimg.cn/large/6313a6d8jw1eqavcuynw4j211o04s40a.jpg)

结果正确。

**`mon_dump`**：使用`dump start_addr len`，输出两个地址之间的内容，模仿gdb的格式，4字节为单位。若没有物理地址映射到对应虚拟地址范围，则输出`pgunmapped`。

```
for (i = 0; va1 < va2; va1 = (uintptr_t)((uint32_t *)va1 + 1), i++){
   if (flushscreen(i, 23*4, 0))
      break;
   if (!(i % 4))
      cprintf("0x%08x:", va1);

   if (checkmapping(va1))
      cprintf("\t0x%08x", *(uint32_t *)va1);
   else
      cprintf("\tpgunmapped");

   if (i % 4 == 3)
      cprintf("\n");
}
```

测试：与`gdb`结果对比

`gdb`：

![gdb](http://ww4.sinaimg.cn/large/6313a6d8jw1eqaymkfcpyj20yc0mgk4i.jpg)

`mon_dump`：

![mon_dump](http://ww3.sinaimg.cn/large/6313a6d8gw1eqbaq0lra2j20su0iqajt.jpg)

结果完全一致。

**`mon_shutdown`**：使用`shutdown`，关闭`JOS`和`qemu`。由于调试过程中经常需要关掉`qemu`重新编译再运行，而关掉`qemu`这个过程操作次数太多(`Ctrl+a c`-->`quit <Enter>`)，而且在`qemu`本身的窗口中按`Ctrl+a c`并无法召出`qemu`控制台，所以就想要写这么一个接口。参考了Github上[chaOS](https://github.com/Kijewski/chaOS/)的代码，具体实现：

```
int
mon_shutdown(int argc, char **argv, struct Trapframe *tf)
{
   const char *s = "Shutdown";

   __asm __volatile ("cli");
   
   for (;;) {
      // (phony) ACPI shutdown (http://forum.osdev.org/viewtopic.php?t=16990)
      // Works for qemu and bochs.
      outw (0xB004, 0x2000);

      // Magic shutdown code for bochs and qemu.
      while(*s) {
         outb (0x8900, *s);
         ++s;
      }

      // Magic code for VMWare. Also a hard lock.
      __asm __volatile ("cli; hlt");
   }
}

```

#### Challenge 3

>Write up an outline of how a kernel could be designed to allow user environments unrestricted use of the full 4GB virtual and linear address space. Hint: the technique is sometimes known as "follow the bouncing kernel." In your design, be sure to address exactly what has to happen when the processor transitions between kernel and user modes, and how the kernel would accomplish such transitions. Also describe how the kernel would access physical memory and I/O devices in this scheme, and how the kernel would access a user environment's virtual address space during system calls and the like. Finally, think about and describe the advantages and disadvantages of such a scheme in terms of flexibility, performance, kernel complexity, and other factors you can think of.

网上能搜到的资料全是Lab的题目`_(:з」∠)_`。参考了Github上一个叫[`jos-mmap`](https://github.com/cmjones/jos-mmap/blob/master/answers-lab2.txt)的项目中的描述，结合自己的理解，应该只要在用户访问虚存中原本无权限的页（比如保存了`IDT`和`BIOS`的物理页`0`、页表结构，还有一些其他预留的页）时，将对应的物理页映射到虚存中另一个位置，再重新为用户分配该页(这个过程只改变映射关系，不改变物理内存中的内容)。这样用户就能使用整个4G的虚存空间了。

**用户态和内核态的转换**

用户态-->内核态过程中，需要`IDT`以定位中断处理例程。要找到`IDT`需要将其从物理内存中映射到虚存空间中某一个固定的位置(比如`0xF0000000`)。此时只需先备份`0xF0000000`之前的页表项，再将`IDT`映射过去即可。后面就跟普通的中断处理过程一样了。

内核态-->用户态：恢复现场，改写PSW转回用户态，然后恢复用户空间的备份的页表项。

**优缺点**

**优点**：用户能用整个4G虚存空间。

**缺点**：这种每次发生权限错误都会重新进行页表的映射，Overhead非常大。


#### Challenge 4

>Since our JOS kernel's memory management system only allocates and frees memory on page granularity, we do not have anything comparable to a general-purpose malloc/free facility that we can use within the kernel. This could be a problem if we want to support certain types of I/O devices that require physically contiguous buffers larger than `4KB` in size, or if we want user-level environments, and not just the kernel, to be able to allocate and map `4MB` superpages for maximum processor efficiency. (See the earlier challenge problem about `PTE_PS`.)
Generalize the kernel's memory allocation system to support pages of a variety of power-of-two allocation unit sizes from `4KB` up to some reasonable maximum of your choice. Be sure you have some way to divide larger allocation units into smaller ones on demand, and to coalesce multiple small allocation units back into larger units when possible. Think about the issues that might arise in such a system.

这个Challenge的要求就是实现一个类似伙伴系统的算法，思路如下：

1. 为4KB~4MB的页面以2为公比，分别维护各自的`page_free_list[i]`，其中$i = \log_2(Pagesize/4KB)$

2. 初始化时（遍历原先的`page_free_list`）将每`1024`块相邻的`page`作为一个`4MB`的free page插入相应的`page_free_list`。

3. 当分配一个大小为`s`的空间时，
   - 若`page_free_list[u]`($2^{u-1}<s\leq2^u$)不为空，则分配`page_free_list[u]`中的一块空间；
   - 否则检查`page_free_list[u+1]`是否为空，不为空则进入下一步，为空则迭代进行，直到找到不为空的free list；若不存在这样的free list，则返回错误；
   - 从找到的`page_free_list[k]`中取出一个块，将其均分后放入`page_free_list[k-1]`，然后对`page_free_list[k-1]`进行同样的操作，直到`k == u`为止；
   - 此时`page_free_list[u]`不为空，从中分配一个块给`s`即可。

4. 当释放一个块的空间时，
   - 将其插回对应的`page_free_list[u]`；
   - 遍历一遍`page_free_list[u]`链表，看有没有与其空间连续的块，若有，则从`page_free_list[u]`中删除这两个块，将它们合并并插入`page_free_list[u+1]`；
   - 若有$2^u == 4MB$，则不进行合并。

具体实现要大量改动lab的代码，而且在`ICS`也做过类似的东西了，当时调试的绝望依然难以忘怀`_(:з」∠)_`，就不实现到代码了。